{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alesordo/LabAI/blob/main/LabAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5oDKTdxZ7nG"
      },
      "outputs": [],
      "source": [
        "#Google Inception pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5y0__pbTWb-s",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Preliminar operations\n",
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        "\n",
        "# Commonly used modules\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import shutil\n",
        "import statistics\n",
        "from os import mkdir\n",
        "import math\n",
        "import pathlib\n",
        "from PIL import Image\n",
        "\n",
        "# Images, plots, display, and visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import IPython\n",
        "from six.moves import urllib\n",
        "import csv\n",
        "\n",
        "#Mounting directories\n",
        "base_dir='/content/drive/MyDrive/Archive'\n",
        "train_dir=base_dir+'/Train'\n",
        "test_dir=base_dir+'/Test'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title OLD - Operazioni preliminari\n",
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        "\n",
        "# Commonly used modules\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import shutil\n",
        "import statistics\n",
        "from os import mkdir\n",
        "import math\n",
        "import pathlib\n",
        "from PIL import Image\n",
        "\n",
        "# Images, plots, display, and visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import IPython\n",
        "from six.moves import urllib\n",
        "import csv\n",
        "\n",
        "\n",
        "#Fixing python random seed\n",
        "random.seed(42)\n",
        "#Fixing numpy random seed\n",
        "np.random.seed(21)\n",
        "\n",
        "#Mounting directories\n",
        "base_dir='/content/drive/MyDrive/GTSRB'\n",
        "train_dir=base_dir+'/Final_Training/Images'\n",
        "test_dir=base_dir+'/Final_Test/Images'\n",
        "validation_dir = base_dir+\"/Final_Validation/Images\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "uyrx-e2bdqlB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlYk34FH-U-Y",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title EXECUTE ONLY ONCE - CREATE NEW CSV - NOT NEEDED I USED KAGGLE\n",
        "#EXECUTE ONLY ONCE\n",
        "#Merging annotation csv files and creating column with relative filepaths\n",
        "n_classes = 43\n",
        "all_annotation_filenames=[]\n",
        "for n_class in tqdm(range(n_classes)) :\n",
        "  n_class_string=str(n_class).zfill(5)\n",
        "  single_annotation_filename=train_dir+'/'+n_class_string+'/'+'GT-'+n_class_string+'.csv'\n",
        "  all_annotation_filenames.append(single_annotation_filename)\n",
        "combined_annotation_array=[]\n",
        "for f in all_annotation_filenames:\n",
        "  single_annotation_df=pd.read_csv(f,sep=';')\n",
        "  single_annotation_df['Filepath'] = single_annotation_df.apply(lambda row: str(row.ClassId).zfill(5)+'/'+row.Filename, axis=1)\n",
        "  combined_annotation_array.append(single_annotation_df)\n",
        "combined_annotation_csv=pd.concat(combined_annotation_array)\n",
        "combined_annotation_csv.to_csv(train_dir+\"/Annotations.csv\", index=False, encoding='utf-8-sig')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYyAsmM08EtH",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Plotting distribution\n",
        "#Plotting training images dimensions' distribution\n",
        "annotation_file=train_dir+\"/Annotations.csv\"\n",
        "data=pd.read_csv(annotation_file)\n",
        "width = data['Width']\n",
        "height = data['Height']\n",
        "fig, ax = plt.subplots(1,2, figsize=(20,10))\n",
        "fig.tight_layout()\n",
        "ax[0].set(xlabel='Width of images')\n",
        "ax[1].set(xlabel='Height of images')\n",
        "sns.histplot(width, ax=ax[0], legend=False, bins=50, kde=True, color='forestgreen')\n",
        "sns.histplot(height, ax=ax[1], legend=False, bins=50, kde=True, color='rebeccapurple')\n",
        "print(statistics.mean(width))\n",
        "print(statistics.mean(height))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0Zq1ri4UPDa",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title OLD - dividing data in folders EXECUTE ONLY ONCE\n",
        "#WARNING! EXECUTE THIS COMMAND ONLY ONCE - OLD\n",
        "#Dividing data into training and validation (25% of the training dataset)\n",
        "\n",
        "#Creating a validation directory\n",
        "os.makedirs(validation_dir)\n",
        "\n",
        "n_classes = 43\n",
        "\n",
        "#Moving data\n",
        "for n_class in tqdm(range(n_classes)) :\n",
        "  n_class_string=str(n_class).zfill(5)\n",
        "  annotation_file='GT-'+n_class_string+'.csv'\n",
        "  dest_class_path = os.path.join(validation_dir, n_class_string)\n",
        "  os.makedirs(dest_class_path)\n",
        "  src_class_path = os.path.join(train_dir, n_class_string)\n",
        "  list_files = os.listdir(src_class_path)\n",
        "  if (annotation_file) in list_files:\n",
        "    list_files.remove(annotation_file)\n",
        "  rand_idx = random.sample(range(len(list_files)), math.ceil(len(list_files)/4))\n",
        "  for idx in rand_idx :\n",
        "    src_file = src_class_path + \"/\" + list_files[idx]\n",
        "    shutil.move(src_file, dest_class_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UyTnh9TrQoB4",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title IDK, to balance ds\n",
        "#TO USE WHEN YOU'LL DEFINE DATAFRAMES, IN ORDER TO SHOW BALANCE/UNBALANCE OF THE DATASET\n",
        "#df[train_dir].value_counts().plot(kind = 'bar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mz_Be3tF5W-g"
      },
      "outputs": [],
      "source": [
        "#Convert path strings into pathlib objects\n",
        "data_path_train = pathlib.Path(train_dir)\n",
        "data_path_validation = pathlib.Path(validation_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-_JId5U4KJh",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title OLD - Convert files from ppm to jpg EXECUTE ONLY ONCE\n",
        "#WARNING! EXECUTE ONLY ONCE - OLD\n",
        "#Function to convert files from .ppm to .jpg (.ppm are not accepted by Tensorflow)\n",
        "#Getting paths of all the images as strings\n",
        "all_image_paths_train = list(data_path_train.glob('*/*.ppm'))\n",
        "for image_path in all_image_paths_train:\n",
        "  directory_name = os.path.dirname(image_path)\n",
        "  image_filename = '{}.jpg'.format(os.path.splitext(os.path.basename(image_path))[0])\n",
        "  new_image_path = os.path.join(directory_name, image_filename)\n",
        "  if(not os.path.exists(new_image_path)):\n",
        "    image=Image.open(image_path)\n",
        "    image.save(new_image_path)\n",
        "\n",
        "all_image_paths_validation = list(data_path_validation.glob('*/*.ppm'))\n",
        "for image_path in all_image_paths_validation:\n",
        "  image=Image.open(image_path)\n",
        "  image_filename = '{}.jpg'.format(os.path.splitext(os.path.basename(image_path))[0])\n",
        "  directory_name = os.path.dirname(image_path)\n",
        "  image.save(os.path.join(directory_name, image_filename))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Convert files from ppm to jpg - NOT NEEDED, I USED KAGGLE'S DATASET\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "75kCxXtRXogE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wH_1dWZ-rpy",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title OLD - to edit filepaths with jpg on csv EXECUTE ONLY ONCE\n",
        "#WARNING! EXECUTE ONLY ONCE\n",
        "#Editing relative filepaths from .ppm to .jpg format\n",
        "annotation_file=train_dir+\"/Annotations.csv\"\n",
        "data=pd.read_csv(annotation_file)\n",
        "data['Filepath'] = data['Filepath'].str.replace('ppm','jpg')\n",
        "data.to_csv(annotation_file)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Fixed variables\n",
        "#Fixed variables\n",
        "WIDTH=224\n",
        "HEIGHT=224\n",
        "N_CLASSES=43\n",
        "BATCH_SIZE=30\n",
        "N_CHANNELS = 3\n",
        "CLASS_NAMES=list(range(N_CLASSES))"
      ],
      "metadata": {
        "id": "1iMD17axS0uT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fr2vtXZYB77",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title OLD - to get images paths\n",
        "#OLD\n",
        "\n",
        "#Fixed variables\n",
        "WIDTH=224\n",
        "HEIGHT=224\n",
        "N_CLASSES=43\n",
        "BATCH_SIZE=30\n",
        "N_CHANNELS = 3\n",
        "CLASS_NAMES=list(range(N_CLASSES))\n",
        "\n",
        "#Getting paths of all the images as strings\n",
        "all_image_paths_train = list(data_path_train.glob('*/*.jpg'))\n",
        "all_image_paths_train = [str(path) for path in all_image_paths_train]\n",
        "\n",
        "all_image_paths_validation = list(data_path_validation.glob('*/*.jpg'))\n",
        "all_image_paths_validation = [str(path) for path in all_image_paths_validation]\n",
        "\n",
        "#Counting number of images in each sets\n",
        "image_count_train = len(all_image_paths_train)\n",
        "image_count_validation = len(all_image_paths_validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_go6egiF0UJz",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title OLD - to get labels from images path\n",
        "#Getting class labels array for each set (through images paths)\n",
        "label_names_train = sorted(int(item.name) for item in data_path_train.glob('*/') if item.is_dir())\n",
        "label_names_validation = sorted(int(item.name) for item in data_path_validation.glob('*/') if item.is_dir())\n",
        "\n",
        "label_to_index_train = dict((name, index) for index,name in enumerate(label_names_train))\n",
        "label_to_index_val = dict((name, index) for index,name in enumerate(label_names_validation))\n",
        "\n",
        "all_image_labels_train = [label_to_index_train[int(pathlib.Path(path).parent.name)] for path in all_image_paths_train]\n",
        "all_image_labels_validation = [label_to_index_val[int(pathlib.Path(path).parent.name)] for path in all_image_paths_validation]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIcv4SUk7MFE",
        "outputId": "57d383a3-c589-46f6-b868-e0f8a551d270",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "39209it [00:39, 999.52it/s]\n"
          ]
        }
      ],
      "source": [
        "#@title OLD - to update bounding box coordinates\n",
        "#Updating bounding boxes coordinates on csv\n",
        "\n",
        "#Loading dataframe\n",
        "df_annotations = pd.read_csv(train_dir+\"/Annotations.csv\")\n",
        "\n",
        "#Updating coordinates\n",
        "for idx, row in tqdm(df_annotations.iterrows()):\n",
        "  w = row['Width']\n",
        "  h = row['Height']\n",
        "  if w > WIDTH:\n",
        "    diff = w - WIDTH\n",
        "    df_annotations.iloc[idx, 5] = df_annotations.iloc[idx]['Roi.X2'] - diff\n",
        "  else:\n",
        "    diff = WIDTH - w\n",
        "    df_annotations.iloc[idx, 5] = df_annotations.iloc[idx]['Roi.X2'] + diff\n",
        "  if h > HEIGHT :\n",
        "    diff = h - HEIGHT\n",
        "    df_annotations.iloc[idx, 6] = df_annotations.iloc[idx]['Roi.Y2'] - diff\n",
        "  else :\n",
        "    diff = HEIGHT - h\n",
        "    df_annotations.iloc[idx, 6] = df_annotations.iloc[idx]['Roi.Y2'] + diff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxYJ7ESAFmS1",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title OLD - to split dataframe with validation\n",
        "#Splitting dataframes into training and validation\n",
        "train_idx_list=[]\n",
        "validation_idx_list=[]\n",
        "print(all_image_paths_train[7763])\n",
        "for path_train in tqdm(all_image_paths_train):\n",
        "  train_idx_list.append(df_annotations[df_annotations['Filepath']==path_train[51:]].index[0])\n",
        "for path_validation in tqdm(all_image_paths_validation):\n",
        "  validation_idx_list.append(df_annotations[df_annotations['Filepath']==path_validation[53:]].index[0])\n",
        "\n",
        "print(len(train_idx_list),len(validation_idx_list))\n",
        "\n",
        "df_train = pd.DataFrame()\n",
        "df_validation = pd.DataFrame()\n",
        "\n",
        "df_train = df_train.append(df_annotations.iloc[train_idx_list], ignore_index = True)\n",
        "df_validation = df_validation.append(df_annotations.iloc[validation_idx_list], ignore_index = True)\n",
        "\n",
        "#Removing everything except bounding box coordinates from dataframes\n",
        "df_train = df_train.drop(['Height', 'Width', 'ClassId', 'Filepath', 'Filename'], axis = 1)\n",
        "df_validation = df_validation.drop(['Height', 'Width', 'ClassId', 'Filepath', 'Filename'], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JoZy_oSQP8GI",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title OLD- to create data generators (important)\n",
        "#Creating data generators\n",
        "def tfdata_generator(images, labels, df, is_training, batch_size=BATCH_SIZE):\n",
        "  #Construct a data generator using tf.Dataset\n",
        "  def parse_function(filename, labels, df):\n",
        "    #Function to preprocess the images\n",
        "    #reading path \n",
        "    image_string = tf.io.read_file(filename)\n",
        "    #decoding image\n",
        "    image = tf.image.decode_jpeg(image_string, channels=N_CHANNELS)\n",
        "    # This will convert to float values in [0, 1]\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    #Adjusting contrast and brightness of the image\n",
        "    if tf.math.reduce_mean(image) < 0.3 :\n",
        "      image = tf.image.adjust_contrast(image, 5)\n",
        "      image = tf.image.adjust_brightness(image, 0.2)\n",
        "    #resize the image\n",
        "    image = tf.image.resize(image, [HEIGHT, WIDTH], method=\"nearest\", preserve_aspect_ratio=False)\n",
        "    # This will convert to float values in [0, 1]\n",
        "    #image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    #one hot coding for label\n",
        "    #y = tf.one_hot(tf.cast(label, tf.uint8), N_CLASSES)\n",
        "    #image = image/255.0\n",
        "    return image, {\"classification\" : labels, \"regression\" : df}\n",
        "    #return image\n",
        "  \n",
        "  ##creating a dataset from tensorslices\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((images, labels, df))\n",
        "  if is_training:\n",
        "    dataset = dataset.repeat(10).shuffle(30000)  # depends on sample size\n",
        "    #dataset = dataset.repeat(10) #10 is the number of epochs\n",
        "  else:\n",
        "    dataset=dataset.repeat(10).shuffle(10000)\n",
        "  # Transform and batch data at the same time\n",
        "  dataset = dataset.map(parse_function)\n",
        "  dataset = dataset.repeat(10)\n",
        "  dataset = dataset.batch(batch_size)\n",
        "  #prefetch the data into CPU/GPU\n",
        "  dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "  return dataset\n",
        "\n",
        "#Train and Validation data generators :\n",
        "tf_image_generator_train = tfdata_generator(all_image_paths_train, all_image_labels_train, df_train, is_training=True, batch_size=BATCH_SIZE)\n",
        "tf_image_generator_val = tfdata_generator(all_image_paths_validation, all_image_labels_validation, df_validation, is_training=False, batch_size=BATCH_SIZE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeBHMs0x0O8a",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title OLD - to show images\n",
        "for i, (image, label) in enumerate(tf_image_generator_train.take(12)):\n",
        "    ax = plt.subplot(4, 4, i + 1)\n",
        "    image1 = image.numpy().astype(\"float32\")\n",
        "    #plt.imshow(image.numpy().astype(\"uint8\"))\n",
        "    plt.imshow(np.squeeze(image1[0]))\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17sMjiPfYq3G"
      },
      "outputs": [],
      "source": [
        "STEPS_PER_EPOCH = len(train_idx_list)//BATCH_SIZE\n",
        "VALIDATION_STEPS = len(validation_idx_list)//BATCH_SIZE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bb70HozKOcz"
      },
      "outputs": [],
      "source": [
        "#VGC-16\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "\n",
        "base_model = VGG16(input_shape = (224, 224, 3), # Shape of our images\n",
        "include_top = False, # Leave out the last fully connected layer\n",
        "weights = 'imagenet')\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(base_model.output)\n",
        "\n",
        "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
        "x = layers.Dense(512, activation='relu')(x)\n",
        "\n",
        "# Add a dropout rate of 0.5\n",
        "x = layers.Dropout(0.5)(x)\n",
        "\n",
        "# Add a final sigmoid layer with 1 node for classification output\n",
        "x = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = tf.keras.models.Model(base_model.input, x)\n",
        "\n",
        "model.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0.0001), loss = 'binary_crossentropy',metrics = ['acc'])\n",
        "\n",
        "vgghist = model.fit(tf_image_generator_train, validation_data = tf_image_generator_val, steps_per_epoch = 100, epochs = 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6U2fPMdXOIxq"
      },
      "outputs": [],
      "source": [
        "%pip install efficientnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "elv-lClANf8R",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title OLD - Efficientnet\n",
        "#EFFICIENTNET\n",
        "\n",
        "import efficientnet.keras as efn\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "\n",
        "base_model = efn.EfficientNetB0(input_shape = (35, 35, 3), include_top = False, weights = 'imagenet')\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(1024, activation=\"relu\")(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "# Add a final sigmoid layer with 1 node for classification output\n",
        "predictions = Dense(1, activation=\"sigmoid\")(x)\n",
        "model_final = Model(inputs = base_model.input, outputs = predictions)\n",
        "\n",
        "model_final.compile(optimizers.RMSprop(lr=0.0001, decay=1e-6),loss='binary_crossentropy',metrics=['accuracy'])\n",
        "eff_history = model_final.fit_generator(tf_image_generator_train, validation_data = tf_image_generator_val, steps_per_epoch = 100, validation_steps=30, epochs = 10)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1iUbKFfTJwchMbybyL9NoDn9L8rUj10Mo",
      "authorship_tag": "ABX9TyNmPJyKz7VJ2tX9v6rK5kD0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}